{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/SingularitySmith/PRUT-Transcriber/blob/main/PRUT_Transcriber4.ipynb",
      "authorship_tag": "ABX9TyOf/7aJbnDHGGECKHnZZHQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SingularitySmith/PRUT-Transcriber/blob/main/PRUT_Transcriber4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "INPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT_MP4\"\n",
        "OUTPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XNgIf7nA1m-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xPXhwtiL1wTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0VKSZg41wQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KUAit7Hp1wHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3xnoJZr1wEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMPLE WORKING TRANSCRIPTION SYSTEM\n",
        "# Based on the approach that was working\n",
        "\n",
        "# ============================================\n",
        "# CELL 1: Complete Setup and Processing\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "# if not os.path.exists('/content/drive'):\n",
        "#    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PCbATlERrLzz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths - adjust these to your actual locations\n",
        "INPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "OUTPUT_PATH = \"/content/drive/My Drive/PRUT-Transcriptions/Transcripts\"\n"
      ],
      "metadata": {
        "id": "nMDOEtSbr6n6",
        "outputId": "e8127ec9-9f59-4116-9dc0-49228c2c2c28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 2: File Discovery and Status\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this to see what files need processing\n",
        "\"\"\"\n",
        "\n",
        "# Get list of audio files\n",
        "mp4_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp4\")))\n",
        "mp3_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp3\")))\n",
        "all_audio_files = mp4_files + mp3_files\n",
        "\n",
        "print(f\"\\nüìÅ Found {len(all_audio_files)} audio files:\")\n",
        "for i, f in enumerate(all_audio_files, 1):\n",
        "    print(f\"  {i}. {os.path.basename(f)}\")\n",
        "\n",
        "# Check what's already been transcribed\n",
        "completed_files = []\n",
        "remaining_files = []\n",
        "\n",
        "for audio_file in all_audio_files:\n",
        "    base_name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "    transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "    if os.path.exists(transcript_path):\n",
        "        completed_files.append(audio_file)\n",
        "    else:\n",
        "        remaining_files.append(audio_file)\n",
        "\n",
        "print(f\"\\nüìä Status:\")\n",
        "print(f\"  ‚úì Completed: {len(completed_files)}\")\n",
        "print(f\"  ‚è≥ Remaining: {len(remaining_files)}\")\n",
        "\n",
        "if remaining_files:\n",
        "    print(f\"\\nüéØ Next file to process: {os.path.basename(remaining_files[0])}\")\n"
      ],
      "metadata": {
        "id": "pVlri5OYr0Hi",
        "outputId": "938fa821-7fcd-4aa1-be27-b6e50c3b0b83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Found 8 audio files:\n",
            "  1. Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "  2. Call Recording - 13Mar25 1130 BK.mp4\n",
            "  3. Call Recording - 13Mar25 1300 HB.mp4\n",
            "  4. Call Recording - 19Mar2025 0800 JD.mp4\n",
            "  5. Call Recording - 19Mar25 0900 - AJ.mp4\n",
            "  6. Call Recording - 19Mar25 1730 - MO.mp4\n",
            "  7. Call Recording - 20Mar2025 1200 LN.mp4\n",
            "  8. Call Recording - 26Mar2025 0830 SA.mp4\n",
            "\n",
            "üìä Status:\n",
            "  ‚úì Completed: 0\n",
            "  ‚è≥ Remaining: 8\n",
            "\n",
            "üéØ Next file to process: Call Recording - 13Mar2025 1200 BPA.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # ============================================\n",
        "    # INSTALL WHISPER (MINIMAL VERSION)\n",
        "    # ============================================\n",
        "\n",
        "    if remaining_files and not os.path.exists('/usr/local/bin/whisper'):\n",
        "        print(\"\\nüì¶ Installing OpenAI Whisper...\")\n",
        "        subprocess.run(['pip', 'install', '-q', 'openai-whisper'], check=True)\n",
        "        print(\"‚úì Whisper installed\")\n",
        ""
      ],
      "metadata": {
        "id": "g6RoUcIHrLKL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # ============================================\n",
        "    # PROCESS FILES ONE BY ONE\n",
        "    # ============================================\n",
        "\n",
        "    if remaining_files:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"STARTING TRANSCRIPTION\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Process only first 3 files to avoid timeout\n",
        "        files_to_process = remaining_files[:3]\n",
        "\n",
        "        for idx, audio_file in enumerate(files_to_process):\n",
        "            base_name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "            output_file = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "            print(f\"\\n[{idx+1}/{len(files_to_process)}] Processing: {os.path.basename(audio_file)}\")\n",
        "\n",
        "            try:\n",
        "                # Use whisper command line (more stable than Python API)\n",
        "                start_time = time.time()\n",
        "\n",
        "                # Run whisper with minimal settings\n",
        "                cmd = [\n",
        "                    'whisper',\n",
        "                    audio_file,\n",
        "                    '--model', 'tiny',\n",
        "                    '--language', 'en',\n",
        "                    '--output_format', 'txt',\n",
        "                    '--output_dir', OUTPUT_PATH,\n",
        "                    '--verbose', 'False'\n",
        "                ]\n",
        "\n",
        "                result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "                if result.returncode == 0:\n",
        "                    # Rename output file to our format\n",
        "                    whisper_output = os.path.join(OUTPUT_PATH, f\"{base_name}.txt\")\n",
        "                    if os.path.exists(whisper_output):\n",
        "                        os.rename(whisper_output, output_file)\n",
        "\n",
        "                    elapsed = time.time() - start_time\n",
        "                    print(f\"‚úì Success! Processed in {elapsed:.1f} seconds\")\n",
        "                    print(f\"  Saved to: {os.path.basename(output_file)}\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Error: {result.stderr}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Failed: {e}\")\n",
        "\n",
        "            # Cool down between files\n",
        "            if idx < len(files_to_process) - 1:\n",
        "                print(\"\\n‚è≥ Cooling down for 5 seconds...\")\n",
        "                time.sleep(5)\n",
        "\n",
        "            # Force garbage collection\n",
        "            gc.collect()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"SESSION COMPLETE\")\n",
        "        print(f\"Processed {len(files_to_process)} files\")\n",
        "        print(f\"Remaining: {len(remaining_files) - len(files_to_process)} files\")\n",
        "        print(\"\\nRun this cell again to continue processing!\")\n",
        "        print(\"=\"*60)\n",
        "    else:\n",
        "        print(\"\\n‚úÖ All files have been transcribed!\")"
      ],
      "metadata": {
        "id": "PKqrMQtjrK8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSHsG6zjrJa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V9\n"
      ],
      "metadata": {
        "id": "zuY7or_9rHdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MANUAL PATH FIX - DIRECT SOLUTION\n",
        "# Run this to manually set the correct path and verify it works\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MANUAL PATH CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Based on your working code, the correct path should be:\n",
        "CORRECT_BASE = \"/content/drive/My Drive\"  # No space in MyDrive\n",
        "CORRECT_SOURCE = f\"{CORRECT_BASE}/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "CORRECT_OUTPUT = f\"{CORRECT_BASE}/PRUT-Transcriptions/Transcripts\"\n",
        "\n",
        "print(f\"Testing path: {CORRECT_SOURCE}\")\n",
        "\n",
        "if os.path.exists(CORRECT_SOURCE):\n",
        "    files = os.listdir(CORRECT_SOURCE)\n",
        "    audio_files = [f for f in files if any(f.lower().endswith(ext)\n",
        "                   for ext in ['.mp4', '.mp3', '.wav', '.m4a', '.flac', '.ogg'])]\n",
        "\n",
        "    print(f\"‚úì Path exists!\")\n",
        "    print(f\"‚úì Found {len(audio_files)} audio files\")\n",
        "\n",
        "    if audio_files:\n",
        "        print(\"\\nAudio files found:\")\n",
        "        for f in audio_files[:5]:\n",
        "            print(f\"  - {f}\")\n",
        "\n",
        "        # Create a fixed configuration file\n",
        "        config = {\n",
        "            \"DRIVE_MOUNT\": CORRECT_BASE,\n",
        "            \"SOURCE_DIR\": CORRECT_SOURCE,\n",
        "            \"OUTPUT_DIR\": CORRECT_OUTPUT,\n",
        "            \"verified\": True,\n",
        "            \"file_count\": len(audio_files)\n",
        "        }\n",
        "\n",
        "        config_path = f\"{CORRECT_BASE}/PRUT-Transcriptions/path_config.json\"\n",
        "        with open(config_path, 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(f\"\\n‚úÖ Configuration saved to: {config_path}\")\n",
        "        print(\"\\nNOW DO THIS:\")\n",
        "        print(\"1. Copy this line:\")\n",
        "        print(f'   SOURCE_DIR = \"{CORRECT_SOURCE}\"')\n",
        "        print(\"2. Paste it at the top of your main transcription code\")\n",
        "        print(\"3. Run the main code again\")\n",
        "else:\n",
        "    print(\"‚úó Path does not exist!\")\n",
        "    print(\"\\nTrying to list what's actually in your PRUT folder...\")\n",
        "\n",
        "    prut_base = f\"{CORRECT_BASE}/PRUT-Transcriptions\"\n",
        "    if os.path.exists(prut_base):\n",
        "        print(f\"\\nContents of {prut_base}:\")\n",
        "        for item in os.listdir(prut_base):\n",
        "            item_path = os.path.join(prut_base, item)\n",
        "            if os.path.isdir(item_path):\n",
        "                print(f\"  üìÅ {item}/\")\n",
        "                # Check inside folders\n",
        "                sub_items = os.listdir(item_path)\n",
        "                for sub in sub_items[:3]:\n",
        "                    print(f\"     - {sub}\")\n",
        "            else:\n",
        "                print(f\"  üìÑ {item}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "JU-JXBjbqC1k",
        "outputId": "2ce1e12d-e659-412d-d775-018a92441bfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "MANUAL PATH CONFIGURATION\n",
            "============================================================\n",
            "Testing path: /content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\n",
            "‚úì Path exists!\n",
            "‚úì Found 8 audio files\n",
            "\n",
            "Audio files found:\n",
            "  - Call Recording - 19Mar25 0900 - AJ.mp4\n",
            "  - Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "  - Call Recording - 26Mar2025 0830 SA.mp4\n",
            "  - Call Recording - 19Mar25 1730 - MO.mp4\n",
            "  - Call Recording - 19Mar2025 0800 JD.mp4\n",
            "\n",
            "‚úÖ Configuration saved to: /content/drive/My Drive/PRUT-Transcriptions/path_config.json\n",
            "\n",
            "NOW DO THIS:\n",
            "1. Copy this line:\n",
            "   SOURCE_DIR = \"/content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\"\n",
            "2. Paste it at the top of your main transcription code\n",
            "3. Run the main code again\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C2w_CAnfp9z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WhisperX Ultra-Resilient Transcription System\n",
        "# Single-cell design with aggressive memory management\n",
        "\n",
        "\"\"\"\n",
        "CODE BLOCK 1: COMPLETE SYSTEM - RUN THIS SINGLE CELL REPEATEDLY\n",
        "This cell contains the entire system and can be run after crashes\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import gc\n",
        "import subprocess\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "LRQ6H_lQmZZX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CODE BLOCK 1.1: CONFIGURATION - FIXED\n",
        "# ============================================\n",
        "\n",
        "# HARDCODED CORRECT PATHS (based on your working code)\n",
        "DRIVE_MOUNT = '/content/drive/My Drive'  # NO SPACE\n",
        "BASE_DIR = f'{DRIVE_MOUNT}/PRUT-Transcriptions'\n",
        "SOURCE_DIR = f'{BASE_DIR}/Recordings_PRUT'\n",
        "OUTPUT_DIR = f'{BASE_DIR}/Transcripts'\n",
        "WAV_DIR = f'{BASE_DIR}/WAV_Cache'\n",
        "CHECKPOINT_FILE = f'{BASE_DIR}/checkpoint.json'\n",
        "LOG_FILE = f'{BASE_DIR}/processing.log'\n",
        "\n",
        "# Create directories\n",
        "for dir_path in [BASE_DIR, OUTPUT_DIR, WAV_DIR]:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "print(f\"Using paths:\")\n",
        "print(f\"  Source: {SOURCE_DIR}\")\n",
        "print(f\"  Output: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "DcmyeMG5mbwi",
        "outputId": "47afab10-65ef-41b5-edf4-390703376c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using paths:\n",
            "  Source: /content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\n",
            "  Output: /content/drive/My Drive/PRUT-Transcriptions/Transcripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.2: LOGGING SYSTEM\n",
        "# ============================================\n",
        "\n",
        "def log_message(message, level=\"INFO\"):\n",
        "    \"\"\"Log to both console and file\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    log_entry = f\"[{timestamp}] {level}: {message}\"\n",
        "    print(log_entry)\n",
        "\n",
        "    try:\n",
        "        with open(LOG_FILE, 'a') as f:\n",
        "            f.write(log_entry + \"\\n\")\n",
        "    except:\n",
        "        pass  # Don't fail if can't write log"
      ],
      "metadata": {
        "id": "Tcq2hw8PmeH2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.3: CHECKPOINT MANAGEMENT\n",
        "# ============================================\n",
        "\n",
        "def load_checkpoint():\n",
        "    \"\"\"Load progress from checkpoint file\"\"\"\n",
        "    if os.path.exists(CHECKPOINT_FILE):\n",
        "        with open(CHECKPOINT_FILE, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return {\n",
        "        'processed_files': [],\n",
        "        'failed_files': {},\n",
        "        'current_mode': 'ultra_minimal',  # Start with absolute minimum\n",
        "        'model_loaded': None,\n",
        "        'last_update': None,\n",
        "        'session_count': 0\n",
        "    }\n",
        "\n",
        "def save_checkpoint(checkpoint):\n",
        "    \"\"\"Save progress to checkpoint file\"\"\"\n",
        "    checkpoint['last_update'] = datetime.now().isoformat()\n",
        "    checkpoint['session_count'] = checkpoint.get('session_count', 0) + 1\n",
        "    with open(CHECKPOINT_FILE, 'w') as f:\n",
        "        json.dump(checkpoint, f, indent=2)\n",
        "    log_message(f\"Checkpoint saved (session #{checkpoint['session_count']})\")"
      ],
      "metadata": {
        "id": "AEumln0BmiKt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.4: PROCESSING MODES\n",
        "# ============================================\n",
        "\n",
        "PROCESSING_MODES = {\n",
        "    'ultra_minimal': {\n",
        "        'method': 'whisper_api',  # Use OpenAI Whisper API directly\n",
        "        'model': 'tiny',           # Smallest possible model\n",
        "        'skip_vad': True,          # Skip voice activity detection\n",
        "        'skip_align': True,        # Skip alignment\n",
        "        'skip_diarize': True,      # Skip diarization\n",
        "        'chunk_duration': 180      # 3-minute chunks\n",
        "    },\n",
        "    'minimal': {\n",
        "        'method': 'whisperx',\n",
        "        'model': 'base',\n",
        "        'skip_vad': True,\n",
        "        'skip_align': False,\n",
        "        'skip_diarize': True,\n",
        "        'chunk_duration': 300\n",
        "    },\n",
        "    'standard': {\n",
        "        'method': 'whisperx',\n",
        "        'model': 'small',\n",
        "        'skip_vad': False,\n",
        "        'skip_align': False,\n",
        "        'skip_diarize': True,\n",
        "        'chunk_duration': 600\n",
        "    },\n",
        "    'high': {\n",
        "        'method': 'whisperx',\n",
        "        'model': 'medium',\n",
        "        'skip_vad': False,\n",
        "        'skip_align': False,\n",
        "        'skip_diarize': False,\n",
        "        'chunk_duration': 900\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "M1eJxiO3mkY6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.5: SAFE DEPENDENCY INSTALLATION\n",
        "# ============================================\n",
        "\n",
        "def ensure_dependencies(mode):\n",
        "    \"\"\"Install only necessary dependencies for current mode\"\"\"\n",
        "    log_message(f\"Checking dependencies for {mode} mode...\")\n",
        "\n",
        "    # Basic dependencies always needed\n",
        "    basic_deps = ['pydub']\n",
        "    for dep in basic_deps:\n",
        "        try:\n",
        "            __import__(dep)\n",
        "        except ImportError:\n",
        "            log_message(f\"Installing {dep}...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', dep])\n",
        "\n",
        "    # FFmpeg\n",
        "    if subprocess.call(['which', 'ffmpeg'], stdout=subprocess.DEVNULL) != 0:\n",
        "        log_message(\"Installing ffmpeg...\")\n",
        "        subprocess.call(['apt-get', '-qq', 'update'])\n",
        "        subprocess.call(['apt-get', '-qq', 'install', 'ffmpeg'])\n",
        "\n",
        "    # Mode-specific dependencies\n",
        "    if PROCESSING_MODES[mode]['method'] == 'whisper_api':\n",
        "        try:\n",
        "            import whisper\n",
        "        except ImportError:\n",
        "            log_message(\"Installing OpenAI Whisper...\")\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'openai-whisper'])\n",
        "\n",
        "    elif PROCESSING_MODES[mode]['method'] == 'whisperx':\n",
        "        try:\n",
        "            import whisperx\n",
        "        except ImportError:\n",
        "            log_message(\"Installing WhisperX...\")\n",
        "            # Install with specific order to avoid conflicts\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'torch==2.0.0', 'torchaudio==2.0.0', '--index-url', 'https://download.pytorch.org/whl/cu118'])\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'git+https://github.com/m-bain/whisperx.git'])"
      ],
      "metadata": {
        "id": "avlZ-PdKmltz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.6: ULTRA-MINIMAL TRANSCRIPTION\n",
        "# ============================================\n",
        "\n",
        "def transcribe_ultra_minimal(audio_path):\n",
        "    \"\"\"Use OpenAI Whisper directly - most stable option\"\"\"\n",
        "    import whisper\n",
        "\n",
        "    log_message(\"Loading tiny Whisper model...\")\n",
        "    model = whisper.load_model(\"tiny\")\n",
        "\n",
        "    log_message(\"Transcribing with OpenAI Whisper...\")\n",
        "    result = model.transcribe(audio_path, language='en')\n",
        "\n",
        "    # Convert to WhisperX-like format\n",
        "    segments = []\n",
        "    if 'segments' in result:\n",
        "        for seg in result['segments']:\n",
        "            segments.append({\n",
        "                'start': seg['start'],\n",
        "                'end': seg['end'],\n",
        "                'text': seg['text']\n",
        "            })\n",
        "    else:\n",
        "        # Fallback if no segments\n",
        "        segments.append({\n",
        "            'start': 0,\n",
        "            'end': 0,\n",
        "            'text': result.get('text', '')\n",
        "        })\n",
        "\n",
        "    # Clean up model\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "    return {'segments': segments}"
      ],
      "metadata": {
        "id": "GYzL9Zkpmlrs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.7: WHISPERX TRANSCRIPTION\n",
        "# ============================================\n",
        "\n",
        "def transcribe_whisperx(audio_path, mode_config):\n",
        "    \"\"\"Use WhisperX with configurable features\"\"\"\n",
        "    import whisperx\n",
        "    import torch\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Load only necessary models\n",
        "    log_message(f\"Loading {mode_config['model']} model on {device}...\")\n",
        "\n",
        "    # Load with minimal configuration\n",
        "    model = whisperx.load_model(\n",
        "        mode_config['model'],\n",
        "        device,\n",
        "        compute_type=\"int8\",  # Always use int8 for stability\n",
        "        language='en',\n",
        "        asr_options={\n",
        "            \"suppress_numerals\": True,\n",
        "            \"max_new_tokens\": None,\n",
        "            \"clip_timestamps\": None,\n",
        "            \"hallucination_silence_threshold\": None,\n",
        "            \"hotwords\": None\n",
        "        } if mode_config['skip_vad'] else {}\n",
        "    )\n",
        "\n",
        "    # Load audio\n",
        "    audio = whisperx.load_audio(audio_path)\n",
        "\n",
        "    # Transcribe with minimal batch size\n",
        "    log_message(\"Transcribing...\")\n",
        "    result = model.transcribe(audio, batch_size=1)\n",
        "\n",
        "    # Optional alignment\n",
        "    if not mode_config['skip_align']:\n",
        "        try:\n",
        "            log_message(\"Aligning transcript...\")\n",
        "            model_a, metadata = whisperx.load_align_model(language_code='en', device=device)\n",
        "            result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device)\n",
        "            del model_a\n",
        "        except Exception as e:\n",
        "            log_message(f\"Alignment failed: {e}\", \"WARNING\")\n",
        "\n",
        "    # Clean up\n",
        "    del model\n",
        "    torch.cuda.empty_cache() if device == \"cuda\" else None\n",
        "    gc.collect()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "de1dLs2VmlpR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.8: AUDIO PROCESSING\n",
        "# ============================================\n",
        "\n",
        "def convert_to_wav(input_path, output_path):\n",
        "    \"\"\"Convert audio file to WAV format\"\"\"\n",
        "    try:\n",
        "        from pydub import AudioSegment\n",
        "        log_message(f\"Converting to WAV: {os.path.basename(input_path)}\")\n",
        "\n",
        "        audio = AudioSegment.from_file(input_path)\n",
        "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "        audio.export(output_path, format=\"wav\")\n",
        "\n",
        "        log_message(f\"Saved WAV to cache: {os.path.basename(output_path)}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        log_message(f\"Conversion failed: {e}\", \"ERROR\")\n",
        "        return False\n",
        "\n",
        "def split_audio_for_processing(wav_path, chunk_duration):\n",
        "    \"\"\"Split audio into smaller chunks\"\"\"\n",
        "    from pydub import AudioSegment\n",
        "\n",
        "    audio = AudioSegment.from_wav(wav_path)\n",
        "    total_duration = len(audio) / 1000  # seconds\n",
        "\n",
        "    if total_duration <= chunk_duration:\n",
        "        return [(wav_path, 0)]  # No need to split\n",
        "\n",
        "    chunks = []\n",
        "    chunk_ms = chunk_duration * 1000\n",
        "\n",
        "    for i in range(0, len(audio), chunk_ms):\n",
        "        chunk = audio[i:i + chunk_ms]\n",
        "        chunk_path = wav_path.replace('.wav', f'_chunk_{i//1000}.wav')\n",
        "        chunk.export(chunk_path, format=\"wav\")\n",
        "        chunks.append((chunk_path, i/1000))\n",
        "\n",
        "    log_message(f\"Split into {len(chunks)} chunks of {chunk_duration}s each\")\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "iOmgmJ4mmlnO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.9: MAIN PROCESSING FUNCTION\n",
        "# ============================================\n",
        "\n",
        "def process_single_file(filepath, checkpoint):\n",
        "    \"\"\"Process a single file with current mode\"\"\"\n",
        "    mode = checkpoint['current_mode']\n",
        "    mode_config = PROCESSING_MODES[mode]\n",
        "    base_name = os.path.splitext(os.path.basename(filepath))[0]\n",
        "\n",
        "    log_message(f\"\\n{'='*60}\")\n",
        "    log_message(f\"Processing: {os.path.basename(filepath)}\")\n",
        "    log_message(f\"Mode: {mode}\")\n",
        "    log_message(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        # Get or create WAV file\n",
        "        wav_path = os.path.join(WAV_DIR, f\"{base_name}.wav\")\n",
        "        if not os.path.exists(wav_path):\n",
        "            if not filepath.endswith('.wav'):\n",
        "                if not convert_to_wav(filepath, wav_path):\n",
        "                    raise Exception(\"Failed to convert to WAV\")\n",
        "            else:\n",
        "                import shutil\n",
        "                shutil.copy2(filepath, wav_path)\n",
        "\n",
        "        # Check file size and split if needed\n",
        "        file_size_mb = os.path.getsize(wav_path) / (1024*1024)\n",
        "        log_message(f\"File size: {file_size_mb:.1f} MB\")\n",
        "\n",
        "        chunks = split_audio_for_processing(wav_path, mode_config['chunk_duration'])\n",
        "        all_segments = []\n",
        "\n",
        "        # Process each chunk\n",
        "        for chunk_idx, (chunk_path, start_offset) in enumerate(chunks):\n",
        "            if len(chunks) > 1:\n",
        "                log_message(f\"Processing chunk {chunk_idx+1}/{len(chunks)}...\")\n",
        "\n",
        "            # Choose transcription method\n",
        "            if mode_config['method'] == 'whisper_api':\n",
        "                result = transcribe_ultra_minimal(chunk_path)\n",
        "            else:\n",
        "                result = transcribe_whisperx(chunk_path, mode_config)\n",
        "\n",
        "            # Adjust timestamps and collect segments\n",
        "            for segment in result.get('segments', []):\n",
        "                segment['start'] = segment.get('start', 0) + start_offset\n",
        "                segment['end'] = segment.get('end', 0) + start_offset\n",
        "                all_segments.append(segment)\n",
        "\n",
        "            # Clean up chunk if it's temporary\n",
        "            if chunk_path != wav_path:\n",
        "                os.remove(chunk_path)\n",
        "\n",
        "            # Force garbage collection after each chunk\n",
        "            gc.collect()\n",
        "            time.sleep(1)  # Brief pause\n",
        "\n",
        "        # Save transcript\n",
        "        output_path = os.path.join(OUTPUT_DIR, f\"{base_name}_transcript.txt\")\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(f\"# Transcription of: {os.path.basename(filepath)}\\n\")\n",
        "            f.write(f\"# Processing mode: {mode}\\n\")\n",
        "            f.write(f\"# Processed on: {datetime.now().isoformat()}\\n\\n\")\n",
        "\n",
        "            for seg_idx, segment in enumerate(all_segments):\n",
        "                start = segment.get('start', 0)\n",
        "                end = segment.get('end', 0)\n",
        "                text = segment.get('text', '').strip()\n",
        "\n",
        "                if text:  # Only write non-empty segments\n",
        "                    f.write(f\"[{start:.2f}-{end:.2f}] {text}\\n\")\n",
        "\n",
        "        log_message(f\"SUCCESS: Saved transcript to {os.path.basename(output_path)}\")\n",
        "\n",
        "        # Update checkpoint\n",
        "        checkpoint['processed_files'].append(os.path.basename(filepath))\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        log_message(f\"FAILED: {e}\", \"ERROR\")\n",
        "\n",
        "        # Log failure\n",
        "        checkpoint['failed_files'][os.path.basename(filepath)] = {\n",
        "            'error': str(e),\n",
        "            'mode': mode,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        save_checkpoint(checkpoint)\n",
        "\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "k6GJ4iG2mllL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.10: GET PENDING FILES\n",
        "# ============================================\n",
        "\n",
        "def get_pending_files(checkpoint):\n",
        "    \"\"\"Get list of files not yet processed\"\"\"\n",
        "    all_files = []\n",
        "    supported_formats = ['.mp4', '.mp3', '.wav', '.m4a', '.flac', '.ogg']\n",
        "\n",
        "    # Check if source directory exists\n",
        "    if not os.path.exists(SOURCE_DIR):\n",
        "        log_message(f\"Source directory not found: {SOURCE_DIR}\", \"ERROR\")\n",
        "        log_message(\"Please check the path or place audio files in this directory\", \"ERROR\")\n",
        "        return None  # Return None to indicate path error\n",
        "\n",
        "    try:\n",
        "        files_in_dir = os.listdir(SOURCE_DIR)\n",
        "        if not files_in_dir:\n",
        "            log_message(f\"Source directory is empty: {SOURCE_DIR}\", \"WARNING\")\n",
        "            return []\n",
        "\n",
        "        for filename in files_in_dir:\n",
        "            if os.path.splitext(filename)[1].lower() in supported_formats:\n",
        "                all_files.append(filename)\n",
        "\n",
        "        if not all_files:\n",
        "            log_message(f\"No audio files found in {SOURCE_DIR}\", \"WARNING\")\n",
        "            log_message(f\"Looking for: {', '.join(supported_formats)}\", \"INFO\")\n",
        "\n",
        "    except Exception as e:\n",
        "        log_message(f\"Error reading source directory: {e}\", \"ERROR\")\n",
        "        return None\n",
        "\n",
        "    # Filter out already processed files\n",
        "    pending = []\n",
        "    for f in all_files:\n",
        "        if f not in checkpoint['processed_files']:\n",
        "            base_name = os.path.splitext(f)[0]\n",
        "            transcript_path = os.path.join(OUTPUT_DIR, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "            if not os.path.exists(transcript_path):\n",
        "                pending.append(f)\n",
        "            else:\n",
        "                # File was processed but not in checkpoint\n",
        "                checkpoint['processed_files'].append(f)\n",
        "                log_message(f\"Found existing transcript for {f}, updating checkpoint\")\n",
        "\n",
        "    return sorted(pending)  # Sort for consistent ordering"
      ],
      "metadata": {
        "id": "vQouee3Lmli8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.11: MAIN EXECUTION\n",
        "# ============================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # Mount Google Drive\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        if not os.path.exists('/content/drive'):\n",
        "            drive.mount('/content/drive')\n",
        "            log_message(\"Google Drive mounted\")\n",
        "\n",
        "            # Re-check mount point after mounting\n",
        "            global DRIVE_MOUNT, BASE_DIR, SOURCE_DIR, OUTPUT_DIR, WAV_DIR, CHECKPOINT_FILE, LOG_FILE\n",
        "            for mount in ['/content/drive/MyDrive', '/content/drive/My Drive']:\n",
        "                if os.path.exists(mount):\n",
        "                    DRIVE_MOUNT = mount\n",
        "                    BASE_DIR = f'{DRIVE_MOUNT}/PRUT-Transcriptions'\n",
        "                    SOURCE_DIR = f'{BASE_DIR}/Recordings_PRUT'\n",
        "                    OUTPUT_DIR = f'{BASE_DIR}/Transcripts'\n",
        "                    WAV_DIR = f'{BASE_DIR}/WAV_Cache'\n",
        "                    CHECKPOINT_FILE = f'{BASE_DIR}/checkpoint.json'\n",
        "                    LOG_FILE = f'{BASE_DIR}/processing.log'\n",
        "\n",
        "                    # Create directories\n",
        "                    for dir_path in [BASE_DIR, SOURCE_DIR, OUTPUT_DIR, WAV_DIR]:\n",
        "                        os.makedirs(dir_path, exist_ok=True)\n",
        "                    break\n",
        "        else:\n",
        "            log_message(\"Google Drive already mounted\")\n",
        "    except Exception as e:\n",
        "        log_message(f\"Could not mount Drive: {e}\", \"WARNING\")\n",
        "\n",
        "    # Show current configuration\n",
        "    log_message(f\"Configuration:\")\n",
        "    log_message(f\"  Source: {SOURCE_DIR}\")\n",
        "    log_message(f\"  Output: {OUTPUT_DIR}\")\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = load_checkpoint()\n",
        "\n",
        "    log_message(\"\\n\" + \"=\"*60)\n",
        "    log_message(f\"SESSION #{checkpoint.get('session_count', 0) + 1} STARTING\")\n",
        "    log_message(f\"Progress: {len(checkpoint['processed_files'])} files completed\")\n",
        "    log_message(f\"Failed: {len(checkpoint['failed_files'])} files\")\n",
        "    log_message(f\"Current mode: {checkpoint['current_mode']}\")\n",
        "    log_message(\"=\"*60)\n",
        "\n",
        "    # Get pending files\n",
        "    pending_files = get_pending_files(checkpoint)\n",
        "\n",
        "    # Check if path error\n",
        "    if pending_files is None:\n",
        "        log_message(\"\\nPath configuration error. Please:\")\n",
        "        log_message(\"1. Run the path finder diagnostic tool to find your files\")\n",
        "        log_message(\"2. Update SOURCE_DIR in the configuration\")\n",
        "        log_message(\"3. Or place audio files in: \" + SOURCE_DIR)\n",
        "        return\n",
        "\n",
        "    log_message(f\"Files remaining: {len(pending_files)}\")\n",
        "\n",
        "    if not pending_files:\n",
        "        # Only upgrade if we actually processed files (not just empty directory)\n",
        "        if len(checkpoint['processed_files']) > 0:\n",
        "            log_message(\"\\nAll files processed in current mode!\")\n",
        "\n",
        "            # Check if we should upgrade mode\n",
        "            modes = list(PROCESSING_MODES.keys())\n",
        "            current_idx = modes.index(checkpoint['current_mode'])\n",
        "\n",
        "            if current_idx < len(modes) - 1:\n",
        "                next_mode = modes[current_idx + 1]\n",
        "                log_message(f\"\\nUpgrading to {next_mode} mode for better quality...\")\n",
        "                checkpoint['current_mode'] = next_mode\n",
        "                checkpoint['processed_files'] = []\n",
        "                checkpoint['failed_files'] = {}\n",
        "                save_checkpoint(checkpoint)\n",
        "                pending_files = get_pending_files(checkpoint)\n",
        "            else:\n",
        "                log_message(\"\\nALL PROCESSING COMPLETE!\")\n",
        "                return\n",
        "        else:\n",
        "            log_message(\"\\nNo audio files found to process.\")\n",
        "            log_message(f\"Please add audio files to: {SOURCE_DIR}\")\n",
        "            log_message(f\"Supported formats: .mp4, .mp3, .wav, .m4a, .flac, .ogg\")\n",
        "            return\n",
        "\n",
        "    # Ensure dependencies for current mode\n",
        "    ensure_dependencies(checkpoint['current_mode'])\n",
        "\n",
        "    # Process files one by one\n",
        "    processed_count = 0\n",
        "    max_files_per_session = 3  # Process fewer files per session for stability\n",
        "\n",
        "    for filename in pending_files[:max_files_per_session]:\n",
        "        filepath = os.path.join(SOURCE_DIR, filename)\n",
        "\n",
        "        # Check if file exists\n",
        "        if not os.path.exists(filepath):\n",
        "            log_message(f\"File not found: {filename}\", \"WARNING\")\n",
        "            continue\n",
        "\n",
        "        success = process_single_file(filepath, checkpoint)\n",
        "        processed_count += 1\n",
        "\n",
        "        # Longer cooldown between files\n",
        "        if processed_count < len(pending_files):\n",
        "            log_message(\"Cooling down for 15 seconds...\")\n",
        "            time.sleep(15)\n",
        "\n",
        "        # Force garbage collection\n",
        "        gc.collect()\n",
        "\n",
        "    # Summary\n",
        "    log_message(\"\\n\" + \"=\"*60)\n",
        "    log_message(f\"SESSION COMPLETE\")\n",
        "    log_message(f\"Processed this session: {processed_count}\")\n",
        "    log_message(f\"Total completed: {len(checkpoint['processed_files'])}\")\n",
        "    log_message(f\"Still pending: {len(pending_files) - processed_count}\")\n",
        "    log_message(\"=\"*60)\n",
        "\n",
        "    if len(pending_files) > processed_count:\n",
        "        log_message(\"\\nRun this cell again to continue processing!\")\n",
        "\n",
        "    # Final cleanup\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "WCd3Ejiymlg5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.12: EXECUTE MAIN\n",
        "# ============================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        log_message(\"\\nProcess interrupted by user\", \"WARNING\")\n",
        "    except Exception as e:\n",
        "        log_message(f\"\\nFATAL ERROR: {e}\", \"ERROR\")\n",
        "        import traceback\n",
        "        log_message(traceback.format_exc(), \"ERROR\")"
      ],
      "metadata": {
        "id": "spIJ2jf5mleV",
        "outputId": "f1abdfb5-bb2f-4817-e173-ea5f707d2788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025-06-18 20:41:11] INFO: Google Drive already mounted\n",
            "[2025-06-18 20:41:11] INFO: Configuration:\n",
            "[2025-06-18 20:41:11] INFO:   Source: /content/drive/My Drive/PRUT-Transcriptions/Recordings_PRUT\n",
            "[2025-06-18 20:41:11] INFO:   Output: /content/drive/My Drive/PRUT-Transcriptions/Transcripts\n",
            "[2025-06-18 20:41:11] INFO: \n",
            "============================================================\n",
            "[2025-06-18 20:41:11] INFO: SESSION #9 STARTING\n",
            "[2025-06-18 20:41:11] INFO: Progress: 8 files completed\n",
            "[2025-06-18 20:41:11] INFO: Failed: 0 files\n",
            "[2025-06-18 20:41:11] INFO: Current mode: ultra_minimal\n",
            "[2025-06-18 20:41:11] INFO: ============================================================\n",
            "[2025-06-18 20:41:11] INFO: Files remaining: 0\n",
            "[2025-06-18 20:41:11] INFO: \n",
            "All files processed in current mode!\n",
            "[2025-06-18 20:41:11] INFO: \n",
            "Upgrading to minimal mode for better quality...\n",
            "[2025-06-18 20:41:11] INFO: Checkpoint saved (session #9)\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 19Mar25 0900 - AJ.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 13Mar2025 1200 BPA.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 26Mar2025 0830 SA.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 19Mar25 1730 - MO.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 19Mar2025 0800 JD.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 13Mar25 1130 BK.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 13Mar25 1300 HB.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Found existing transcript for Call Recording - 20Mar2025 1200 LN.mp4, updating checkpoint\n",
            "[2025-06-18 20:41:11] INFO: Checking dependencies for minimal mode...\n",
            "[2025-06-18 20:41:11] INFO: Installing WhisperX...\n",
            "[2025-06-18 20:42:50] WARNING: \n",
            "Process interrupted by user\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# CODE BLOCK 1.13: USAGE INSTRUCTIONS\n",
        "# ============================================\n",
        "\n",
        "\"\"\"\n",
        "CRASH-PROOF TRANSCRIPTION SYSTEM\n",
        "\n",
        "SETUP:\n",
        "1. GPU Runtime: Use T4 or CPU (system adapts automatically)\n",
        "2. Run the PATH FINDER tool first to locate your audio files\n",
        "3. Update SOURCE_DIR if needed\n",
        "4. Run this single cell - it handles everything\n",
        "\n",
        "AFTER CRASH:\n",
        "1. Reconnect to runtime\n",
        "2. Run this same cell again\n",
        "3. It automatically resumes from checkpoint\n",
        "\n",
        "PROCESSING MODES (AUTOMATIC PROGRESSION):\n",
        "1. ultra_minimal: OpenAI Whisper tiny model (most stable)\n",
        "2. minimal: WhisperX base model, no VAD\n",
        "3. standard: WhisperX small model with VAD\n",
        "4. high: WhisperX medium model with diarization\n",
        "\n",
        "FEATURES:\n",
        "- Saves after EVERY file\n",
        "- Logs all operations\n",
        "- 3-minute chunks for stability\n",
        "- Automatic mode progression\n",
        "- Crash recovery built-in\n",
        "\n",
        "MONITORING:\n",
        "- Check progress: cat /content/drive/MyDrive/PRUT-Transcriptions/checkpoint.json\n",
        "- View logs: cat /content/drive/MyDrive/PRUT-Transcriptions/processing.log\n",
        "\n",
        "TROUBLESHOOTING:\n",
        "- If crashes persist, manually edit checkpoint.json:\n",
        "  \"current_mode\": \"ultra_minimal\"\n",
        "- Delete specific files from \"processed_files\" array to reprocess\n",
        "\n",
        "PATH ISSUES:\n",
        "If you see \"Source directory not found\", try:\n",
        "1. Run the path finder diagnostic tool\n",
        "2. Manually set the correct path at the top of this code\n",
        "3. Or create the expected directory and add files:\n",
        "   !mkdir -p \"/content/drive/MyDrive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "\n",
        "MANUAL PATH SETUP:\n",
        "# If your files are in a different location, update the configuration:\n",
        "SOURCE_DIR = '/content/drive/MyDrive/YOUR_ACTUAL_PATH/audio_files'\n",
        "\"\"\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "lqoJylqTmlcH",
        "outputId": "6f3d6dae-1432-4b9f-a1d8-a7e42216e067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCRASH-PROOF TRANSCRIPTION SYSTEM\\n\\nSETUP:\\n1. GPU Runtime: Use T4 or CPU (system adapts automatically)\\n2. Run the PATH FINDER tool first to locate your audio files\\n3. Update SOURCE_DIR if needed\\n4. Run this single cell - it handles everything\\n\\nAFTER CRASH:\\n1. Reconnect to runtime\\n2. Run this same cell again\\n3. It automatically resumes from checkpoint\\n\\nPROCESSING MODES (AUTOMATIC PROGRESSION):\\n1. ultra_minimal: OpenAI Whisper tiny model (most stable)\\n2. minimal: WhisperX base model, no VAD\\n3. standard: WhisperX small model with VAD\\n4. high: WhisperX medium model with diarization\\n\\nFEATURES:\\n- Saves after EVERY file\\n- Logs all operations\\n- 3-minute chunks for stability\\n- Automatic mode progression\\n- Crash recovery built-in\\n\\nMONITORING:\\n- Check progress: cat /content/drive/MyDrive/PRUT-Transcriptions/checkpoint.json\\n- View logs: cat /content/drive/MyDrive/PRUT-Transcriptions/processing.log\\n\\nTROUBLESHOOTING:\\n- If crashes persist, manually edit checkpoint.json:\\n  \"current_mode\": \"ultra_minimal\"\\n- Delete specific files from \"processed_files\" array to reprocess\\n\\nPATH ISSUES:\\nIf you see \"Source directory not found\", try:\\n1. Run the path finder diagnostic tool\\n2. Manually set the correct path at the top of this code\\n3. Or create the expected directory and add files:\\n   !mkdir -p \"/content/drive/MyDrive/PRUT-Transcriptions/Recordings_PRUT\"\\n   \\nMANUAL PATH SETUP:\\n# If your files are in a different location, update the configuration:\\nSOURCE_DIR = \\'/content/drive/MyDrive/YOUR_ACTUAL_PATH/audio_files\\'\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCxZFFOamlZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-tDGH5vmlRa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}