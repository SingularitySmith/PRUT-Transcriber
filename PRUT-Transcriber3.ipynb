{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOgdz4+B1uZPeDLrhUQH1wN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SingularitySmith/PRUT-Transcriber/blob/main/PRUT-Transcriber3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 1: Setup and Imports\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this first to set up your environment and import necessary modules\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"ğŸ¯ Setting up Whisper.cpp transcription environment...\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths - adjust these to your actual locations\n",
        "INPUT_PATH = \"/content/drive/MyDrive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/PRUT-Transcriptions/Transcripts\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Install whisper.cpp if not already done\n",
        "if not os.path.exists('/content/whisper.cpp'):\n",
        "    print(\"Installing whisper.cpp...\")\n",
        "    !git clone https://github.com/ggerganov/whisper.cpp\n",
        "    !cd whisper.cpp && make\n",
        "else:\n",
        "    print(\"âœ“ Whisper.cpp already installed\")\n",
        "\n",
        "# Download model if not already present\n",
        "model_path = \"/content/whisper.cpp/models/ggml-base.en.bin\"\n",
        "if not os.path.exists(model_path):\n",
        "    print(\"Downloading base.en model...\")\n",
        "    !cd whisper.cpp && ./models/download-ggml-model.sh base.en\n",
        "else:\n",
        "    print(\"âœ“ Model already downloaded\")\n",
        "\n",
        "print(\"\\nâœ… Setup complete!\")\n"
      ],
      "metadata": {
        "id": "Wta_1CX9ANYd",
        "outputId": "250b25e3-fd3c-4ba8-e244-58b096d8201c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ Setting up Whisper.cpp transcription environment...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ“ Whisper.cpp already installed\n",
            "âœ“ Model already downloaded\n",
            "\n",
            "âœ… Setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzWfFviMAUW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 2: File Discovery and Status\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this to see what files need processing\n",
        "\"\"\"\n",
        "\n",
        "# Get list of audio files\n",
        "mp4_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp4\")))\n",
        "mp3_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp3\")))\n",
        "all_audio_files = mp4_files + mp3_files\n",
        "\n",
        "print(f\"\\nğŸ“ Found {len(all_audio_files)} audio files:\")\n",
        "for i, f in enumerate(all_audio_files, 1):\n",
        "    print(f\"  {i}. {os.path.basename(f)}\")\n",
        "\n",
        "# Check what's already been transcribed\n",
        "completed_files = []\n",
        "remaining_files = []\n",
        "\n",
        "for audio_file in all_audio_files:\n",
        "    base_name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "    transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "    if os.path.exists(transcript_path):\n",
        "        completed_files.append(audio_file)\n",
        "    else:\n",
        "        remaining_files.append(audio_file)\n",
        "\n",
        "print(f\"\\nğŸ“Š Status:\")\n",
        "print(f\"  âœ“ Completed: {len(completed_files)}\")\n",
        "print(f\"  â³ Remaining: {len(remaining_files)}\")\n",
        "\n",
        "if remaining_files:\n",
        "    print(f\"\\nğŸ¯ Next file to process: {os.path.basename(remaining_files[0])}\")\n"
      ],
      "metadata": {
        "id": "4KJ15EexAUNa",
        "outputId": "3ce7c077-9abf-448e-d2a0-15b022bb1d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“ Found 8 audio files:\n",
            "  1. Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "  2. Call Recording - 13Mar25 1130 BK.mp4\n",
            "  3. Call Recording - 13Mar25 1300 HB.mp4\n",
            "  4. Call Recording - 19Mar2025 0800 JD.mp4\n",
            "  5. Call Recording - 19Mar25 0900 - AJ.mp4\n",
            "  6. Call Recording - 19Mar25 1730 - MO.mp4\n",
            "  7. Call Recording - 20Mar2025 1200 LN.mp4\n",
            "  8. Call Recording - 26Mar2025 0830 SA.mp4\n",
            "\n",
            "ğŸ“Š Status:\n",
            "  âœ“ Completed: 0\n",
            "  â³ Remaining: 8\n",
            "\n",
            "ğŸ¯ Next file to process: Call Recording - 13Mar2025 1200 BPA.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 3: Audio Conversion Function\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Helper function to convert MP4/MP3 to WAV for whisper.cpp\n",
        "\"\"\"\n",
        "\n",
        "def convert_to_wav(input_path):\n",
        "    \"\"\"Convert audio file to 16kHz WAV format required by whisper.cpp\"\"\"\n",
        "    output_path = f\"/tmp/{os.path.basename(input_path)}.wav\"\n",
        "\n",
        "    # Skip if already WAV\n",
        "    if input_path.lower().endswith('.wav'):\n",
        "        return input_path\n",
        "\n",
        "    print(f\"Converting to WAV: {os.path.basename(input_path)}\")\n",
        "\n",
        "    # Use ffmpeg to convert to 16kHz mono WAV\n",
        "    cmd = [\n",
        "        'ffmpeg', '-i', input_path,\n",
        "        '-ar', '16000',      # 16kHz sample rate\n",
        "        '-ac', '1',          # Mono\n",
        "        '-c:a', 'pcm_s16le', # 16-bit PCM\n",
        "        '-y',                # Overwrite\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(f\"âœ“ Converted successfully\")\n",
        "        return output_path\n",
        "    else:\n",
        "        print(f\"âŒ Conversion failed: {result.stderr}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "I2r2BKzIAUIv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 4: Process Single File (Run Repeatedly)\n",
        "# ============================================\n",
        "\"\"\"\n",
        "RUN THIS BLOCK REPEATEDLY - Once for each file\n",
        "Processes exactly one file then stops\n",
        "\"\"\"\n",
        "\n",
        "if remaining_files:\n",
        "    # Get next file to process\n",
        "    current_file = remaining_files[0]\n",
        "    base_name = os.path.splitext(os.path.basename(current_file))[0]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ¯ Processing: {os.path.basename(current_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        # Convert to WAV\n",
        "        wav_path = convert_to_wav(current_file)\n",
        "        if not wav_path:\n",
        "            raise Exception(\"Failed to convert audio file\")\n",
        "\n",
        "        # Prepare output path\n",
        "        transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "        # Run whisper.cpp\n",
        "        print(\"\\nğŸ“ Transcribing with whisper.cpp...\")\n",
        "        print(\"(This may take several minutes)\")\n",
        "\n",
        "        # First, let's find where the binary actually is\n",
        "        possible_paths = [\n",
        "            '/content/whisper.cpp/build/bin/whisper-cli',\n",
        "            '/content/whisper.cpp/bin/whisper-cli',\n",
        "            '/content/whisper.cpp/main'\n",
        "        ]\n",
        "\n",
        "        whisper_binary = None\n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                whisper_binary = path\n",
        "                print(f\"âœ“ Found whisper binary at: {path}\")\n",
        "                break\n",
        "\n",
        "        if not whisper_binary:\n",
        "            # If still not found, let's search for it\n",
        "            result = subprocess.run(['find', '/content/whisper.cpp', '-name', 'whisper-cli', '-type', 'f'],\n",
        "                                  capture_output=True, text=True)\n",
        "            if result.stdout:\n",
        "                whisper_binary = result.stdout.strip().split('\\n')[0]\n",
        "                print(f\"âœ“ Found whisper binary at: {whisper_binary}\")\n",
        "            else:\n",
        "                raise Exception(\"Cannot find whisper-cli binary. Try recompiling with: !cd whisper.cpp && make clean && make\")\n",
        "\n",
        "        cmd = [\n",
        "            whisper_binary,\n",
        "            '-m', '/content/whisper.cpp/models/ggml-base.en.bin',\n",
        "            '-f', wav_path,\n",
        "            '-of', transcript_path.replace('.txt', ''),  # whisper.cpp adds extension\n",
        "            '--print-colors',\n",
        "            '--print-progress',\n",
        "            '-l', 'en',\n",
        "            '-t', '8',  # Use 8 threads\n",
        "            '--no-timestamps'  # Remove if you want timestamps\n",
        "        ]\n",
        "\n",
        "        # Run transcription\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"\\nâœ… Transcription complete!\")\n",
        "\n",
        "            # Read and format the transcript\n",
        "            with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Add header to transcript\n",
        "            final_content = f\"# Transcript: {base_name}\\n\\n\"\n",
        "            final_content += f\"**File**: {os.path.basename(current_file)}\\n\"\n",
        "            final_content += f\"**Processed**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
        "            final_content += \"---\\n\\n\"\n",
        "            final_content += content\n",
        "\n",
        "            # Save formatted transcript\n",
        "            with open(transcript_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(final_content)\n",
        "\n",
        "            print(f\"âœ“ Saved: {transcript_path}\")\n",
        "\n",
        "            # Update remaining files\n",
        "            remaining_files.pop(0)\n",
        "\n",
        "            print(f\"\\nğŸ“Š Progress: {len(all_audio_files) - len(remaining_files)}/{len(all_audio_files)}\")\n",
        "\n",
        "            if remaining_files:\n",
        "                print(f\"\\nğŸ”„ Next up: {os.path.basename(remaining_files[0])}\")\n",
        "                print(\"Run this block again to process the next file\")\n",
        "            else:\n",
        "                print(\"\\nğŸ‰ All files processed!\")\n",
        "\n",
        "        else:\n",
        "            print(f\"\\nâŒ Transcription failed\")\n",
        "            print(f\"Error: {result.stderr}\")\n",
        "\n",
        "        # Clean up temporary WAV file\n",
        "        if wav_path != current_file and os.path.exists(wav_path):\n",
        "            os.remove(wav_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Error: {str(e)}\")\n",
        "        print(\"Try running this block again\")\n",
        "\n",
        "else:\n",
        "    print(\"âœ… All files have been processed!\")\n",
        "    print(f\"\\nğŸ“ Transcripts saved in: {OUTPUT_PATH}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "qdTtWuDoAUDW",
        "outputId": "08d0f364-88d0-49ef-a27a-c3cf53053c05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ¯ Processing: Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "============================================================\n",
            "Converting to WAV: Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "âœ“ Converted successfully\n",
            "\n",
            "ğŸ“ Transcribing with whisper.cpp...\n",
            "(This may take several minutes)\n",
            "âœ“ Found whisper binary at: /content/whisper.cpp/build/bin/whisper-cli\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 5: Alternative - Use Larger Model\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Optional: Download and use a larger model for better accuracy\n",
        "\"\"\"\n",
        "\n",
        "print(\"Available models:\")\n",
        "print(\"1. tiny.en    (39 MB) - Fastest, least accurate\")\n",
        "print(\"2. base.en    (142 MB) - Good balance (currently using)\")\n",
        "print(\"3. small.en   (466 MB) - Better accuracy\")\n",
        "print(\"4. medium.en  (1.5 GB) - High accuracy\")\n",
        "print(\"5. large-v3   (3.1 GB) - Best accuracy\")\n",
        "\n",
        "model_choice = input(\"\\nEnter model name to download (or 'skip'): \")\n",
        "\n",
        "if model_choice != 'skip' and model_choice in ['tiny.en', 'base.en', 'small.en', 'medium.en', 'large-v3']:\n",
        "    print(f\"\\nDownloading {model_choice} model...\")\n",
        "    !cd whisper.cpp && ./models/download-ggml-model.sh {model_choice}\n",
        "    print(f\"\\nâœ“ Model downloaded. Update the model path in Block 4 to use it.\")\n"
      ],
      "metadata": {
        "id": "yekl9jrKAPNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 6: Check All Transcripts\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this anytime to see all completed transcripts\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ“Š Transcription Summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "transcripts = glob.glob(os.path.join(OUTPUT_PATH, \"*_transcript.txt\"))\n",
        "print(f\"\\nTotal transcripts: {len(transcripts)}\")\n",
        "\n",
        "total_size = 0\n",
        "for t in sorted(transcripts):\n",
        "    size = os.path.getsize(t) / 1024\n",
        "    total_size += size\n",
        "    print(f\"  âœ“ {os.path.basename(t)} ({size:.1f} KB)\")\n",
        "\n",
        "print(f\"\\nTotal size: {total_size:.1f} KB\")\n",
        "\n",
        "# Show sample from first transcript\n",
        "if transcripts:\n",
        "    print(f\"\\nğŸ“„ Sample from {os.path.basename(transcripts[0])}:\")\n",
        "    with open(transcripts[0], 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        print(\"\".join(lines[:10]) + \"...\")\n"
      ],
      "metadata": {
        "id": "yKgFtyQsAPLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 7: Emergency Cleanup\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this if you need to clean up temporary files or restart\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ§¹ Cleaning up temporary files...\")\n",
        "\n",
        "# Remove temporary WAV files\n",
        "tmp_files = glob.glob(\"/tmp/*.wav\")\n",
        "for f in tmp_files:\n",
        "    os.remove(f)\n",
        "    print(f\"  Removed: {os.path.basename(f)}\")\n",
        "\n",
        "print(\"\\nâœ“ Cleanup complete\")\n",
        "\n",
        "# Show disk usage\n",
        "!df -h /tmp"
      ],
      "metadata": {
        "id": "LwZMgKQcAPJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lygdCroyAO77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kiyfaemNAO5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ALTERNATIVE: Whisper.cpp - No Python dependencies\n",
        "!git clone https://github.com/ggerganov/whisper.cpp\n",
        "!cd whisper.cpp && make\n",
        "\n",
        "# Download model\n",
        "!cd whisper.cpp && ./models/download-ggml-model.sh base.en\n",
        "\n",
        "# Transcribe\n",
        "!cd whisper.cpp && ./main -m models/ggml-base.en.bin -f your_audio.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCDCI8Djhpjr",
        "outputId": "529f4754-ef9d-481c-db86-6f55f278fa7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'whisper.cpp'...\n",
            "remote: Enumerating objects: 20144, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 20144 (delta 95), reused 84 (delta 84), pack-reused 20001 (from 2)\u001b[K\n",
            "Receiving objects: 100% (20144/20144), 23.61 MiB | 7.33 MiB/s, done.\n",
            "Resolving deltas: 100% (14082/14082), done.\n",
            "cmake -B build \n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- GGML_SYSTEM_ARCH: x86\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- Configuring done (1.7s)\n",
            "-- Generating done (0.1s)\n",
            "-- Build files have been written to: /content/whisper.cpp/build\n",
            "cmake --build build --config Release\n",
            "gmake[1]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[2]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[  1%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml.c.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-alloc.c.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-backend.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-opt.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/ggml-threading.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-base.dir/ggml-quants.c.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-base.dir/gguf.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32m\u001b[1mLinking CXX shared library libggml-base.so\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 17%] Built target ggml-base\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 19%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.c.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ggml-cpu.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/repack.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/hbm.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/quants.c.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/traits.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/amx.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/amx/mmq.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/binary-ops.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/unary-ops.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/vec.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/ops.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding C object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/quants.c.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml-cpu.dir/ggml-cpu/arch/x86/repack.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32m\u001b[1mLinking CXX shared library libggml-cpu.so\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 47%] Built target ggml-cpu\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 49%] \u001b[32mBuilding CXX object ggml/src/CMakeFiles/ggml.dir/ggml-backend-reg.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared library libggml.so\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 50%] Built target ggml\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 52%] \u001b[32mBuilding CXX object src/CMakeFiles/whisper.dir/whisper.cpp.o\u001b[0m\n",
            "[ 54%] \u001b[32m\u001b[1mLinking CXX shared library libwhisper.so\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 54%] Built target whisper\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 56%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common-ggml.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/common-whisper.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object examples/CMakeFiles/common.dir/grammar-parser.cpp.o\u001b[0m\n",
            "[ 64%] \u001b[32m\u001b[1mLinking CXX static library libcommon.a\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 64%] Built target common\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 66%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-vad.dir/test-vad.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-vad\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 68%] Built target test-vad\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 70%] \u001b[32mBuilding CXX object tests/CMakeFiles/test-vad-full.dir/test-vad-full.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32m\u001b[1mLinking CXX executable ../bin/test-vad-full\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 72%] Built target test-vad-full\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 74%] \u001b[32mBuilding CXX object examples/cli/CMakeFiles/whisper-cli.dir/cli.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-cli\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 76%] Built target whisper-cli\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 78%] \u001b[32mBuilding CXX object examples/bench/CMakeFiles/whisper-bench.dir/bench.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-bench\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 80%] Built target whisper-bench\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 82%] \u001b[32mBuilding CXX object examples/server/CMakeFiles/whisper-server.dir/server.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/whisper-server\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 84%] Built target whisper-server\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 86%] \u001b[32mBuilding CXX object examples/quantize/CMakeFiles/quantize.dir/quantize.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/quantize\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 88%] Built target quantize\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 90%] \u001b[32mBuilding CXX object examples/vad-speech-segments/CMakeFiles/vad-speech-segments.dir/speech.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/vad-speech-segments\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 92%] Built target vad-speech-segments\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 94%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/main.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/main\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[ 96%] Built target main\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[3]: Entering directory '/content/whisper.cpp/build'\n",
            "[ 98%] \u001b[32mBuilding CXX object examples/deprecation-warning/CMakeFiles/bench.dir/deprecation-warning.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/bench\u001b[0m\n",
            "gmake[3]: Leaving directory '/content/whisper.cpp/build'\n",
            "[100%] Built target bench\n",
            "gmake[2]: Leaving directory '/content/whisper.cpp/build'\n",
            "gmake[1]: Leaving directory '/content/whisper.cpp/build'\n",
            "Downloading ggml model base.en from 'https://huggingface.co/ggerganov/whisper.cpp' ...\n",
            "ggml-base.en.bin    100%[===================>] 141.11M   372MB/s    in 0.4s    \n",
            "Done! Model 'base.en' saved in '/content/whisper.cpp/models/ggml-base.en.bin'\n",
            "You can now use it like this:\n",
            "\n",
            "  $ ./build/bin/whisper-cli -m /content/whisper.cpp/models/ggml-base.en.bin -f samples/jfk.wav\n",
            "\n",
            "/bin/bash: line 1: ./main: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8xn1HqcdetqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d196824b-2035-42bb-f720-7e486210a92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ Setting up minimal transcription environment...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ“ Basic setup complete\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# BLOCK 1: Minimal Setup - Run Once Per Session\n",
        "# ============================================\n",
        "\"\"\"\n",
        "This block sets up the absolute minimum required for transcription.\n",
        "No speaker diarization, no fancy features - just pure transcription.\n",
        "\"\"\"\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"ğŸ¯ Setting up minimal transcription environment...\")\n",
        "\n",
        "# Install only what we absolutely need\n",
        "!pip install -q openai-whisper==20231117\n",
        "!pip install -q ffmpeg-python\n",
        "\n",
        "print(\"âœ“ Basic setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 1: Setup and Imports\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this first to set up your environment and import necessary modules\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"ğŸ¯ Setting up Whisper.cpp transcription environment...\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths - adjust these to your actual locations\n",
        "INPUT_PATH = \"/content/drive/MyDrive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/PRUT-Transcriptions/Transcripts\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Install whisper.cpp if not already done\n",
        "if not os.path.exists('/content/whisper.cpp'):\n",
        "    print(\"Installing whisper.cpp...\")\n",
        "    !git clone https://github.com/ggerganov/whisper.cpp\n",
        "    !cd whisper.cpp && make\n",
        "else:\n",
        "    print(\"âœ“ Whisper.cpp already installed\")\n",
        "\n",
        "# Download model if not already present\n",
        "model_path = \"/content/whisper.cpp/models/ggml-base.en.bin\"\n",
        "if not os.path.exists(model_path):\n",
        "    print(\"Downloading base.en model...\")\n",
        "    !cd whisper.cpp && ./models/download-ggml-model.sh base.en\n",
        "else:\n",
        "    print(\"âœ“ Model already downloaded\")\n",
        "\n",
        "print(\"\\nâœ… Setup complete!\")"
      ],
      "metadata": {
        "id": "Y3O5-hZg-gZM",
        "outputId": "22c51206-b1e6-4dfb-b36d-5d8a3a0886f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ¯ Setting up Whisper.cpp transcription environment...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ“ Whisper.cpp already installed\n",
            "âœ“ Model already downloaded\n",
            "\n",
            "âœ… Setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 2: File Discovery and Status\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this to see what files need processing\n",
        "\"\"\"\n",
        "\n",
        "# Get list of audio files\n",
        "mp4_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp4\")))\n",
        "mp3_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp3\")))\n",
        "all_audio_files = mp4_files + mp3_files\n",
        "\n",
        "print(f\"\\nğŸ“ Found {len(all_audio_files)} audio files:\")\n",
        "for i, f in enumerate(all_audio_files, 1):\n",
        "    print(f\"  {i}. {os.path.basename(f)}\")\n",
        "\n",
        "# Check what's already been transcribed\n",
        "completed_files = []\n",
        "remaining_files = []\n",
        "\n",
        "for audio_file in all_audio_files:\n",
        "    base_name = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "    transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "    if os.path.exists(transcript_path):\n",
        "        completed_files.append(audio_file)\n",
        "    else:\n",
        "        remaining_files.append(audio_file)\n",
        "\n",
        "print(f\"\\nğŸ“Š Status:\")\n",
        "print(f\"  âœ“ Completed: {len(completed_files)}\")\n",
        "print(f\"  â³ Remaining: {len(remaining_files)}\")\n",
        "\n",
        "if remaining_files:\n",
        "    print(f\"\\nğŸ¯ Next file to process: {os.path.basename(remaining_files[0])}\")"
      ],
      "metadata": {
        "id": "W5dqjlvf-nwS",
        "outputId": "f39d075a-df75-49a0-c501-88c72c441c1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“ Found 8 audio files:\n",
            "  1. Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "  2. Call Recording - 13Mar25 1130 BK.mp4\n",
            "  3. Call Recording - 13Mar25 1300 HB.mp4\n",
            "  4. Call Recording - 19Mar2025 0800 JD.mp4\n",
            "  5. Call Recording - 19Mar25 0900 - AJ.mp4\n",
            "  6. Call Recording - 19Mar25 1730 - MO.mp4\n",
            "  7. Call Recording - 20Mar2025 1200 LN.mp4\n",
            "  8. Call Recording - 26Mar2025 0830 SA.mp4\n",
            "\n",
            "ğŸ“Š Status:\n",
            "  âœ“ Completed: 0\n",
            "  â³ Remaining: 8\n",
            "\n",
            "ğŸ¯ Next file to process: Call Recording - 13Mar2025 1200 BPA.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DBkLZRlM_iMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 3: Audio Conversion Function\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Helper function to convert MP4/MP3 to WAV for whisper.cpp\n",
        "\"\"\"\n",
        "\n",
        "def convert_to_wav(input_path):\n",
        "    \"\"\"Convert audio file to 16kHz WAV format required by whisper.cpp\"\"\"\n",
        "    output_path = f\"/tmp/{os.path.basename(input_path)}.wav\"\n",
        "\n",
        "    # Skip if already WAV\n",
        "    if input_path.lower().endswith('.wav'):\n",
        "        return input_path\n",
        "\n",
        "    print(f\"Converting to WAV: {os.path.basename(input_path)}\")\n",
        "\n",
        "    # Use ffmpeg to convert to 16kHz mono WAV\n",
        "    cmd = [\n",
        "        'ffmpeg', '-i', input_path,\n",
        "        '-ar', '16000',      # 16kHz sample rate\n",
        "        '-ac', '1',          # Mono\n",
        "        '-c:a', 'pcm_s16le', # 16-bit PCM\n",
        "        '-y',                # Overwrite\n",
        "        output_path\n",
        "    ]\n",
        "\n",
        "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "    if result.returncode == 0:\n",
        "        print(f\"âœ“ Converted successfully\")\n",
        "        return output_path\n",
        "    else:\n",
        "        print(f\"âŒ Conversion failed: {result.stderr}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "21GvrXOr-npR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 4: Process Single File (Run Repeatedly)\n",
        "# ============================================\n",
        "\"\"\"\n",
        "RUN THIS BLOCK REPEATEDLY - Once for each file\n",
        "Processes exactly one file then stops\n",
        "\"\"\"\n",
        "\n",
        "if remaining_files:\n",
        "    # Get next file to process\n",
        "    current_file = remaining_files[0]\n",
        "    base_name = os.path.splitext(os.path.basename(current_file))[0]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"ğŸ¯ Processing: {os.path.basename(current_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        # Convert to WAV\n",
        "        wav_path = convert_to_wav(current_file)\n",
        "        if not wav_path:\n",
        "            raise Exception(\"Failed to convert audio file\")\n",
        "\n",
        "        # Prepare output path\n",
        "        transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.txt\")\n",
        "\n",
        "        # Run whisper.cpp\n",
        "        print(\"\\nğŸ“ Transcribing with whisper.cpp...\")\n",
        "        print(\"(This may take several minutes)\")\n",
        "\n",
        "        cmd = [\n",
        "            '/content/whisper.cpp/bin/whisper-cli',\n",
        "            '-m', '/content/whisper.cpp/models/ggml-base.en.bin',\n",
        "            '-f', wav_path,\n",
        "            '-of', transcript_path.replace('.txt', ''),  # whisper.cpp adds extension\n",
        "            '--print-colors',\n",
        "            '--print-progress',\n",
        "            '-l', 'en',\n",
        "            '-t', '8',  # Use 8 threads\n",
        "            '--no-timestamps'  # Remove if you want timestamps\n",
        "        ]\n",
        "\n",
        "        # Run transcription\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"\\nâœ… Transcription complete!\")\n",
        "\n",
        "            # Read and format the transcript\n",
        "            with open(transcript_path, 'r', encoding='utf-8') as f:\n",
        "                content = f.read()\n",
        "\n",
        "            # Add header to transcript\n",
        "            final_content = f\"# Transcript: {base_name}\\n\\n\"\n",
        "            final_content += f\"**File**: {os.path.basename(current_file)}\\n\"\n",
        "            final_content += f\"**Processed**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\"\n",
        "            final_content += \"---\\n\\n\"\n",
        "            final_content += content\n",
        "\n",
        "            # Save formatted transcript\n",
        "            with open(transcript_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(final_content)\n",
        "\n",
        "            print(f\"âœ“ Saved: {transcript_path}\")\n",
        "\n",
        "            # Update remaining files\n",
        "            remaining_files.pop(0)\n",
        "\n",
        "            print(f\"\\nğŸ“Š Progress: {len(all_audio_files) - len(remaining_files)}/{len(all_audio_files)}\")\n",
        "\n",
        "            if remaining_files:\n",
        "                print(f\"\\nğŸ”„ Next up: {os.path.basename(remaining_files[0])}\")\n",
        "                print(\"Run this block again to process the next file\")\n",
        "            else:\n",
        "                print(\"\\nğŸ‰ All files processed!\")\n",
        "\n",
        "        else:\n",
        "            print(f\"\\nâŒ Transcription failed\")\n",
        "            print(f\"Error: {result.stderr}\")\n",
        "\n",
        "        # Clean up temporary WAV file\n",
        "        if wav_path != current_file and os.path.exists(wav_path):\n",
        "            os.remove(wav_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Error: {str(e)}\")\n",
        "        print(\"Try running this block again\")\n",
        "\n",
        "else:\n",
        "    print(\"âœ… All files have been processed!\")\n",
        "    print(f\"\\nğŸ“ Transcripts saved in: {OUTPUT_PATH}\")"
      ],
      "metadata": {
        "id": "qogISl1K-nNp",
        "outputId": "c77e1df1-1ee3-4c82-8136-3c22bceda03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸ¯ Processing: Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "============================================================\n",
            "Converting to WAV: Call Recording - 13Mar2025 1200 BPA.mp4\n",
            "âœ“ Converted successfully\n",
            "\n",
            "ğŸ“ Transcribing with whisper.cpp...\n",
            "(This may take several minutes)\n",
            "\n",
            "âŒ Error: [Errno 2] No such file or directory: '/content/whisper.cpp/bin/whisper-cli'\n",
            "Try running this block again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 5: Alternative - Use Larger Model\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Optional: Download and use a larger model for better accuracy\n",
        "\"\"\"\n",
        "\n",
        "print(\"Available models:\")\n",
        "print(\"1. tiny.en    (39 MB) - Fastest, least accurate\")\n",
        "print(\"2. base.en    (142 MB) - Good balance (currently using)\")\n",
        "print(\"3. small.en   (466 MB) - Better accuracy\")\n",
        "print(\"4. medium.en  (1.5 GB) - High accuracy\")\n",
        "print(\"5. large-v3   (3.1 GB) - Best accuracy\")\n",
        "\n",
        "model_choice = input(\"\\nEnter model name to download (or 'skip'): \")\n",
        "\n",
        "if model_choice != 'skip' and model_choice in ['tiny.en', 'base.en', 'small.en', 'medium.en', 'large-v3']:\n",
        "    print(f\"\\nDownloading {model_choice} model...\")\n",
        "    !cd whisper.cpp && ./models/download-ggml-model.sh {model_choice}\n",
        "    print(f\"\\nâœ“ Model downloaded. Update the model path in Block 4 to use it.\")"
      ],
      "metadata": {
        "id": "9m4aXLxJ-ygm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 6: Check All Transcripts\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this anytime to see all completed transcripts\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ“Š Transcription Summary\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "transcripts = glob.glob(os.path.join(OUTPUT_PATH, \"*_transcript.txt\"))\n",
        "print(f\"\\nTotal transcripts: {len(transcripts)}\")\n",
        "\n",
        "total_size = 0\n",
        "for t in sorted(transcripts):\n",
        "    size = os.path.getsize(t) / 1024\n",
        "    total_size += size\n",
        "    print(f\"  âœ“ {os.path.basename(t)} ({size:.1f} KB)\")\n",
        "\n",
        "print(f\"\\nTotal size: {total_size:.1f} KB\")\n",
        "\n",
        "# Show sample from first transcript\n",
        "if transcripts:\n",
        "    print(f\"\\nğŸ“„ Sample from {os.path.basename(transcripts[0])}:\")\n",
        "    with open(transcripts[0], 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "        print(\"\".join(lines[:10]) + \"...\")"
      ],
      "metadata": {
        "id": "DSySpP23-yY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# BLOCK 7: Emergency Cleanup\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this if you need to clean up temporary files or restart\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ§¹ Cleaning up temporary files...\")\n",
        "\n",
        "# Remove temporary WAV files\n",
        "tmp_files = glob.glob(\"/tmp/*.wav\")\n",
        "for f in tmp_files:\n",
        "    os.remove(f)\n",
        "    print(f\"  Removed: {os.path.basename(f)}\")\n",
        "\n",
        "print(\"\\nâœ“ Cleanup complete\")\n",
        "\n",
        "# Show disk usage\n",
        "!df -h /tmp"
      ],
      "metadata": {
        "id": "5bncoPTM-53Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ltAxink-51j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oJMpQ9nk-5zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xHxxF2jG-5w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 2: Mount Drive and Setup Paths\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this once per session to mount your Google Drive\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Configure your paths here\n",
        "INPUT_PATH = \"/content/drive/MyDrive/PRUT-Transcriptions/Recordings_PRUT\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/PRUT-Transcriptions/Transcripts\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Get list of files\n",
        "import glob\n",
        "mp4_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp4\")))\n",
        "mp3_files = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.mp3\")))\n",
        "all_files = mp4_files + mp3_files\n",
        "\n",
        "print(f\"\\nFound {len(all_files)} audio files\")\n",
        "\n",
        "# Check what's already done\n",
        "completed = []\n",
        "for f in all_files:\n",
        "    base_name = os.path.splitext(os.path.basename(f))[0]\n",
        "    transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.md\")\n",
        "    if os.path.exists(transcript_path):\n",
        "        completed.append(base_name)\n",
        "\n",
        "print(f\"Already completed: {len(completed)}\")\n",
        "print(f\"Remaining: {len(all_files) - len(completed)}\")\n",
        "\n",
        "# Create a list of files to process\n",
        "remaining_files = []\n",
        "for f in all_files:\n",
        "    base_name = os.path.splitext(os.path.basename(f))[0]\n",
        "    if base_name not in completed:\n",
        "        remaining_files.append(f)\n",
        "\n",
        "print(\"\\nFiles to process:\")\n",
        "for i, f in enumerate(remaining_files):\n",
        "    print(f\"{i+1}. {os.path.basename(f)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "pwBTtqcBfO3N",
        "outputId": "07b2b556-a12c-483c-9e0e-b02275eae678"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1812225544>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Create output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Get list of files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 3: Process Single File\n",
        "# ============================================\n",
        "\"\"\"\n",
        "RUN THIS BLOCK REPEATEDLY - ONCE FOR EACH FILE\n",
        "It will automatically process the next unprocessed file\n",
        "\"\"\"\n",
        "\n",
        "import whisper\n",
        "import datetime\n",
        "import gc\n",
        "\n",
        "if remaining_files:\n",
        "    # Get the next file to process\n",
        "    current_file = remaining_files[0]\n",
        "    base_name = os.path.splitext(os.path.basename(current_file))[0]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Processing: {os.path.basename(current_file)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        # Load Whisper model (base model for speed/memory)\n",
        "        print(\"Loading Whisper model...\")\n",
        "        model = whisper.load_model(\"large\")\n",
        "\n",
        "        # Transcribe\n",
        "        print(\"Transcribing (this may take a few minutes)...\")\n",
        "        result = model.transcribe(\n",
        "            current_file,\n",
        "            language=\"en\",\n",
        "            word_timestamps=True,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Save transcript\n",
        "        transcript_path = os.path.join(OUTPUT_PATH, f\"{base_name}_transcript.md\")\n",
        "\n",
        "        with open(transcript_path, 'w', encoding='utf-8') as f:\n",
        "            # Header\n",
        "            f.write(f\"# Transcript: {base_name}\\n\\n\")\n",
        "            f.write(f\"**File**: {os.path.basename(current_file)}\\n\")\n",
        "            f.write(f\"**Processed**: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"**Duration**: {result.get('duration', 'Unknown')} seconds\\n\\n\")\n",
        "            f.write(\"---\\n\\n\")\n",
        "\n",
        "            # Segments with timestamps\n",
        "            for segment in result['segments']:\n",
        "                start = segment['start']\n",
        "                end = segment['end']\n",
        "                text = segment['text'].strip()\n",
        "\n",
        "                # Keep all text including fillers\n",
        "                f.write(f\"[{start:.2f}s - {end:.2f}s] {text}\\n\\n\")\n",
        "\n",
        "        print(f\"\\nâœ… Successfully saved: {transcript_path}\")\n",
        "\n",
        "        # Update remaining files list\n",
        "        remaining_files.pop(0)\n",
        "\n",
        "        print(f\"\\nğŸ“Š Progress: {len(all_files) - len(remaining_files)}/{len(all_files)} completed\")\n",
        "        print(f\"Files remaining: {len(remaining_files)}\")\n",
        "\n",
        "        if remaining_files:\n",
        "            print(\"\\nğŸ”„ Run this block again to process the next file\")\n",
        "        else:\n",
        "            print(\"\\nğŸ‰ All files processed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Error: {str(e)}\")\n",
        "        print(\"Try running this block again\")\n",
        "\n",
        "    finally:\n",
        "        # Clean up memory\n",
        "        if 'model' in locals():\n",
        "            del model\n",
        "        gc.collect()\n",
        "\n",
        "else:\n",
        "    print(\"âœ… All files have been processed!\")\n",
        "    print(f\"Check your transcripts in: {OUTPUT_PATH}\")\n"
      ],
      "metadata": {
        "id": "vmbEvUwYfQqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 4: Check Progress (Optional)\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Run this anytime to see your progress\n",
        "\"\"\"\n",
        "\n",
        "print(\"ğŸ“Š Transcription Progress Report\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# List all completed transcripts\n",
        "transcripts = glob.glob(os.path.join(OUTPUT_PATH, \"*_transcript.md\"))\n",
        "print(f\"\\nCompleted transcripts: {len(transcripts)}\")\n",
        "\n",
        "for t in sorted(transcripts):\n",
        "    size_kb = os.path.getsize(t) / 1024\n",
        "    print(f\"  âœ“ {os.path.basename(t)} ({size_kb:.1f} KB)\")\n",
        "\n",
        "# Show remaining files\n",
        "all_bases = [os.path.splitext(os.path.basename(f))[0] for f in all_files]\n",
        "completed_bases = [os.path.basename(t).replace('_transcript.md', '') for t in transcripts]\n",
        "remaining_bases = [b for b in all_bases if b not in completed_bases]\n",
        "\n",
        "if remaining_bases:\n",
        "    print(f\"\\nRemaining files ({len(remaining_bases)}):\")\n",
        "    for r in remaining_bases:\n",
        "        print(f\"  â³ {r}\")\n",
        "else:\n",
        "    print(\"\\nâœ… All files transcribed!\")\n"
      ],
      "metadata": {
        "id": "PB7KqDNZfSOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================\n",
        "# BLOCK 5: Convert Single Transcript to Simple Format\n",
        "# ============================================\n",
        "\"\"\"\n",
        "Optional: Creates a simplified version without timestamps\n",
        "\"\"\"\n",
        "\n",
        "# List available transcripts\n",
        "transcripts = glob.glob(os.path.join(OUTPUT_PATH, \"*_transcript.md\"))\n",
        "print(\"Available transcripts:\")\n",
        "for i, t in enumerate(transcripts):\n",
        "    print(f\"{i+1}. {os.path.basename(t)}\")\n",
        "\n",
        "# Select which one to simplify\n",
        "choice = input(\"\\nEnter number to create simplified version (or 'skip'): \")\n",
        "\n",
        "if choice != 'skip' and choice.isdigit():\n",
        "    idx = int(choice) - 1\n",
        "    if 0 <= idx < len(transcripts):\n",
        "        source_path = transcripts[idx]\n",
        "\n",
        "        # Read transcript\n",
        "        with open(source_path, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Extract just the text (remove timestamps)\n",
        "        import re\n",
        "        pattern = r'\\[\\d+\\.\\d+s - \\d+\\.\\d+s\\] (.+)'\n",
        "        matches = re.findall(pattern, content)\n",
        "\n",
        "        # Save simplified version\n",
        "        simple_path = source_path.replace('_transcript.md', '_simple.txt')\n",
        "        with open(simple_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(' '.join(matches))\n",
        "\n",
        "        print(f\"âœ“ Created simplified version: {os.path.basename(simple_path)}\")"
      ],
      "metadata": {
        "id": "G8IHHR9CfTis"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}